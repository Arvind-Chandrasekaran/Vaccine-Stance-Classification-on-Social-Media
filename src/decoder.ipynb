{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0650d1",
   "metadata": {},
   "source": [
    "## Decoder Transformer Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271e163",
   "metadata": {},
   "source": [
    "### Model - GPT Models\n",
    "\n",
    "\n",
    "Aim : To prompt engineer, finetune GPT models \n",
    "Tools : OpenAI API (by google search)\n",
    "\n",
    "How to use OpenAI API\n",
    "- OpenAI API Documentation:  API Reference + Docs  https://platform.openai.com/docs/api-reference/introduction\n",
    "- Sample code for different tasks: OpenAI Cookbook  https://cookbook.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY_2\")\n",
    "\n",
    "openai.api_key = key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8a3b8",
   "metadata": {},
   "source": [
    "#### Baseline \n",
    "##### 1- Naive\n",
    "##### 2- Explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa04285",
   "metadata": {},
   "source": [
    "##### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative\n",
    "\n",
    "post = \"My friend got sick after vaccine, now my parents don't want to vaccinate me. What should i do?\"\n",
    "\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in inferring people's sentiment towards vaccination.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "\n",
    "        Infer the reddit post author's sentiment towards vaccination as positive or negative or neutral \\n post: {post}\n",
    "\n",
    "\"\"\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff765a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"..\\input_data\\input_output_test.csv\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "\n",
    "for post in tqdm(df[\"input\"]):\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in inferring people's sentiment towards vaccination.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        \n",
    "         Infer the reddit post author's sentiment towards vaccination as positive or negative or neutral \\n post: {post}\n",
    "     \n",
    "        \"\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                messages=messages,\n",
    "                temperature=0.0\n",
    "        )\n",
    "        \n",
    "        predictions.append(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709699b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Quantiative Results\n",
    "\n",
    "import re\n",
    "\n",
    "cleaned = []\n",
    "for text in predictions:\n",
    "    match = re.search(r'\\b(Positive|Negative|Neutral)\\b', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        cleaned.append(match.group(1).capitalize())  # normalize case\n",
    "    else:\n",
    "        cleaned.append(\"Unknown\")\n",
    "\n",
    "print(len(cleaned))\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Quantiative Results\n",
    "\n",
    "df[\"pred\"] = cleaned\n",
    "\n",
    "\n",
    "output_path = r\"..\\prediction\\input_output_test_prediction_naive_baseline_gpt4.1_4.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560f476",
   "metadata": {},
   "source": [
    "##### Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative\n",
    "\n",
    "post = \"My friend got sick after vaccine, now my parents don't want to vaccinate me. What should i do?\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"The positive stance includes posts that support vaccination, show genuine interest in taking it, encourage others, discourage negative sentiment towards vaccination, and counter the anti-vaccine community.\n",
    "        The negative stance includes posts that oppose vaccination, lack interest in getting vaccinated, discourage others from taking the vaccine, and counter the vaccine community.\n",
    "        The neutral stance consists of posts that are not clearly positive or negative. Posts can share experiences (can be painful), but the intention is not to discourage vaccination.\"\"\"},\n",
    "        \n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        You are an expert in vaccine stance inference. Using the above information, infer the stance of the following Reddit post \\n post: {post} \n",
    "        \"\"\"}\n",
    "        ]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantiative \n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"..\\input_data\\input_output_test.csv\")\n",
    "\n",
    "predictions1 = []\n",
    "\n",
    "\n",
    "for post in tqdm(df[\"input\"]):\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"The positive stance includes posts that support vaccination, show genuine interest in taking it, encourage others, discourage negative sentiment towards vaccination, and counter the anti-vaccine community.\n",
    "        The negative stance includes posts that oppose vaccination, lack interest in getting vaccinated, discourage others from taking the vaccine, and counter the vaccine community.\n",
    "        The neutral stance consists of posts that are not clearly positive or negative. Posts can share experiences (can be painful), but the intention is not to discourage vaccination.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"With the above information, infer the reddit post author's sentiment towards vaccination. \\n post: {post} \n",
    "        \"\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "                model=\"gpt-4.1-2025-04-14\",\n",
    "                messages=messages,\n",
    "                temperature=0.0\n",
    "        )\n",
    "        \n",
    "        predictions1.append(response.choices[0].message.content)\n",
    "\n",
    "print(len(predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Quantiative Results\n",
    "\n",
    "import re\n",
    "\n",
    "cleaned = []\n",
    "for text in predictions1:\n",
    "    match = re.search(r'\\b(Positive|Negative|Neutral)\\b', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        cleaned.append(match.group(1).capitalize())  # normalize case\n",
    "    else:\n",
    "        cleaned.append(\"Unknown\")\n",
    "\n",
    "print(len(cleaned))\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a702c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Quantiative Results\n",
    "\n",
    "df[\"pred\"] = cleaned\n",
    "\n",
    "\n",
    "output_path = r\"..\\prediction\\filename.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504315b2",
   "metadata": {},
   "source": [
    "#### Role-Based Incremental Coaching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9c714",
   "metadata": {},
   "source": [
    "Role Based knowledge Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\t\t{\"role\": \"system\", \"content\": \"\"\"You are an expert in inferring a postâ€™s stance towards vaccination. \n",
    "       \t\t\tVaccine Stance is of 3 types - \n",
    "\t\t\tPositive: Posts that support vaccination, show genuine interest in taking it, encourage others, discourage negative sentiment towards vaccination, and counter the anti-vaccine community. \n",
    "\t\t\tNegative: Posts that oppose vaccination, lack interest in getting vaccinated, discourage others from taking the vaccine, and counter the vaccine community. \n",
    "\t\t\tNeutral: Posts that are not clearly Positive or Negative. It could be sharing experience (can be painful) but the intention is not to discourage vaccination.\"\"\"},\n",
    "\t\t{\"role\": \"user\", \"content\": \"\"\" List some common linguistic cues present in textual Reddit posts that contain vaccine sentiment that can help infer the sentiment of the post.\"\"\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    messages=messages,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78387a8",
   "metadata": {},
   "source": [
    "Incremental Coaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative \n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"..\\input_data\\input_output_test.csv\")\n",
    "\n",
    "predictions2 = []\n",
    "\n",
    "\n",
    "for post in tqdm(df[\"input\"]):\n",
    "\n",
    "    messages_temp = messages.copy()\n",
    "    \n",
    " \n",
    "\n",
    "    prompt_simplified = f\"\"\" post: {post} Simplify the language of the post without changing its meaning. Capture the key points and express them in a clear and concise manner \"\"\"\n",
    "\n",
    "\n",
    "    messages_temp.append({\"role\": \"user\", \"content\": f\"{prompt_simplified}\"})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        messages=messages_temp,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    prompt_sentiment = \"Infer the post author's sentiment towards vaccination, with all the information. (Return only the sentiment (positive/negative/neutral))\"\n",
    "\n",
    "    messages_temp.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    messages_temp.append({\"role\": \"user\", \"content\": f\"{prompt_sentiment}\"})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        messages=messages_temp,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    predictions2.append(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "print(len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca391553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Quantitative Results\n",
    "\n",
    "df[\"pred\"] = predictions2\n",
    "\n",
    "\n",
    "output_path = r\"..\\prediction\\filename.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514fedb",
   "metadata": {},
   "source": [
    "#### DSPy\n",
    "\n",
    "Aim : To optimise the prompt engineered & finetuned GPT Model Performance using DSPy.   \n",
    "DSpy Documentation: https://dspy.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24e20c",
   "metadata": {},
   "source": [
    "##### 1. DSPy Simple Module (Module Used - Chain of Thought) \n",
    "Selected after reading all modules' desciptions, involves a reasoning step, can improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy \n",
    "\n",
    "dspy.configure(lm = dspy.LM(\"openai/gpt-4.1-2025-04-14\", temperature = 0, api_key = key, cache=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af82ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature Definition\n",
    "from typing import Literal\n",
    "\n",
    "class vaccine_stance_signature(dspy.Signature):\n",
    "        \"\"\"\n",
    "        Stance towards vaccination is of 3 types: \n",
    "        positive: Posts that support vaccination, show genuine interest in taking it, encourage others, discourage negative sentiment towards vaccination, and counter the anti-vaccine community.\n",
    "        negative: Posts that oppose vaccination, lack interest in getting vaccinated, discourage others from taking the vaccine, and counter the vaccine community.\n",
    "        neutral: Posts that are not clearly positive or negative. Posts can share experiences (can be painful), but the intention is not to discourage vaccination.\n",
    "        \"\"\"\n",
    "\n",
    "        post : str = dspy.InputField(desc = \"Social media post from which the poster's stance, towards vaccination, needs to be inferred.\")\n",
    "        stance : Literal[\"positive\", \"negative\", \"neutral\"]  = dspy.OutputField(desc = \"One worded stance label.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ba219",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cot = dspy.ChainOfThought(vaccine_stance_signature)\n",
    "simple_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cda8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stance = simple_cot(post = \"people always hate vaccines\")\n",
    "stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e513d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"..\\..\\..\\..\\input_data\\input_output_test.csv\")  \n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for post in tqdm(df[\"input\"]):\n",
    "        stance = simple_cot(post = post)\n",
    "        predictions.append(stance.stance)\n",
    "        \n",
    "\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b0d8b0",
   "metadata": {},
   "source": [
    "##### 2. dspy.BootstrapFewShotWithRandomSearch modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class BootstrapFewShotWithRandomSearch_modified:\n",
    "    def __init__(self, base_cot_module, t=16, n=4, k=16, temperature=0):\n",
    "        \n",
    "        self.base = base_cot_module\n",
    "        self.t = t\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def fit(self, train_data, valid_data):\n",
    "\n",
    "        best_f1 = -1\n",
    "        best_examples = None\n",
    "\n",
    "        for trial in range(self.t):\n",
    "            candidate_idxs = random.sample(range(len(train_data)), self.n)\n",
    "            candidate_subset = [train_data[i] for i in candidate_idxs]\n",
    "\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            for text, gold_label in valid_data:\n",
    "                result = self.base.predict(text, temperature=self.temperature)\n",
    "                y_true.append(gold_label)\n",
    "                y_pred.append(result[\"answer\"])\n",
    "\n",
    "            trial_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "            solved_examples = []\n",
    "\n",
    "            for text, gold_label in train_data:\n",
    "                result = self.base.predict(text, temperature=self.temperature)\n",
    "                if result[\"answer\"] == gold_label:\n",
    "                    solved_examples.append({\n",
    "                        \"input\": text,\n",
    "                        \"label\": gold_label,\n",
    "                        \"reasoning\": result[\"reasoning\"]\n",
    "                    })\n",
    "\n",
    "\n",
    "            if len(solved_examples) >= self.k:\n",
    "                solved_examples = random.sample(solved_examples, self.k)\n",
    "\n",
    "\n",
    "            few_shot_examples = {\n",
    "                \"prompt_examples\": candidate_subset,\n",
    "                \"cot_examples\": solved_examples\n",
    "            }\n",
    "\n",
    "\n",
    "            if trial_f1 > best_f1:\n",
    "                best_f1 = trial_f1\n",
    "                best_examples = few_shot_examples\n",
    "\n",
    "\n",
    "        self.best_config = best_examples\n",
    "        self.best_f1 = best_f1\n",
    "        return best_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059231a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BootstrapFewShotWithRandomSearch_modified(\n",
    "    base_cot_module=simple_cot,   # your DSPy CoT module\n",
    "    t=16,\n",
    "    n=4,\n",
    "    k=16,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "train_data = pd.read_csv(r\"..\\..\\..\\..\\input_data\\input_output_train_shuffled_90.csv\").to_dict(orient=\"records\")\n",
    "valid_data = pd.read_csv(r\"..\\..\\..\\..\\input_data\\input_output_validation_shuffled_360.csv\").to_dict(orient=\"records\")\n",
    "\n",
    "best_few_shot = optimizer.fit(train_data, valid_data)\n",
    "\n",
    "print(\"Best macro-F1:\", optimizer.best_f1)\n",
    "print(\"Selected few-shot examples:\", best_few_shot)  #saved at ../input_data/demos.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51331760",
   "metadata": {},
   "source": [
    "#### Finetunening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e92a0",
   "metadata": {},
   "source": [
    "##### Finetuning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Upload\n",
    "# File Only Accepted in JSONL Format\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Your OpenAI API Key\n",
    "OPENAI_API_KEY = key\n",
    "\n",
    "# API endpoint\n",
    "url = 'https://api.openai.com/v1/files'\n",
    "\n",
    "# Headers with authorization\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {OPENAI_API_KEY}'\n",
    "}\n",
    "\n",
    "\n",
    "file_path = r\"..\\input_data\\vaccine_sentiment_test_formatted.jsonl\"\n",
    "\n",
    "# Ensure the file exists\n",
    "if not os.path.isfile(file_path):\n",
    "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "# Prepare data and file for upload\n",
    "data = {\n",
    "    'purpose': 'fine-tune'\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'file': (\n",
    "        os.path.basename(file_path), \n",
    "        open(file_path, 'rb'), \n",
    "        'application/jsonl'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, headers=headers, data=data, files=files)\n",
    "\n",
    "# Close the file after upload\n",
    "files['file'][1].close()\n",
    "\n",
    "# Display response\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning job Start \n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "API_KEY = key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "\n",
    "training_file_id = \"training-file-name\"     # From the previous file upload response (training file - 450*3)\n",
    "validation_file_id =\"validation-file-name\"    # From the previous file upload response (test file - 50*2 + 52)\n",
    "\n",
    "MODEL_NAME = \"gpt-4.1-2025-04-14\"\n",
    "\n",
    "url = \"https://api.openai.com/v1/fine_tuning/jobs\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "payload = {\n",
    "    \"training_file\": training_file_id,\n",
    "    \"validation_file\": validation_file_id,\n",
    "    \"model\": MODEL_NAME ,\n",
    "        \"hyperparameters\": {\n",
    "        \"n_epochs\": 3, \n",
    "        # rest are default values\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(\"Status:\", response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel a fine-tuning job already running\n",
    "\n",
    "job_id = \"ftjobID\"  \n",
    "url = f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}/cancel\"\n",
    "\n",
    "response = requests.post(url, headers=headers)\n",
    "print(\"Cancel status:\", response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838de330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the fine-tuning job\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "API_KEY = key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "\n",
    "job_id = \"ftjob-ID\"\n",
    "\n",
    "\n",
    "url = f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "print(\"HTTP\", response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the events of a fine-tuning job events to check the loss on validation file \n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=key)\n",
    "\n",
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuning job details\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "API_KEY = key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "\n",
    "file_id = \"file-jobID\"             \n",
    "output_path = r\"..\\prediction\\filename.csv\"        \n",
    "\n",
    "\n",
    "url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "with requests.get(url, headers=headers, stream=True) as resp:\n",
    "    resp.raise_for_status()  \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "print(f\"Saved result to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eac0f7",
   "metadata": {},
   "source": [
    "##### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative Test\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "API_KEY = key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "\n",
    "MODEL_NAME = \"fine-tuned model id\" # Obtained after fine-tuning from the saved details\n",
    "url = \"https://api.openai.com/v1/responses\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "post  = \"\"\n",
    "\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"input\": post, \n",
    "    \"temperature\": 0\n",
    "    }\n",
    "resp = requests.post(url, headers=headers, json=payload)\n",
    "resp.raise_for_status()\n",
    "\n",
    "\n",
    "data = resp.json()\n",
    "\n",
    "model_output = data.get(\"response\") or data.get(\"choices\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "print(\"Output:\", data[\"output\"][0][\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Test\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "API_KEY = key\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY variable\")\n",
    "\n",
    "\n",
    "input_path  = r\"..\\input_data\\input_output_test.csv\"  \n",
    "output_path = r\"..\\prediction\\filename.csv\"\n",
    "MODEL_NAME  = \"fine-tuned model id\" # Obtained after fine-tuning from the saved details\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_path, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "raw_responses    = []\n",
    "\n",
    "\n",
    "url = \"https://api.openai.com/v1/responses\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    user_input = row.get(\"input\")  \n",
    "    \n",
    "    resp = requests.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json={\"model\": MODEL_NAME, \"input\": user_input, \"temperature\": 0}\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    \n",
    "    \n",
    "    raw = data[\"output\"][0][\"content\"][0][\"text\"].strip().lower()\n",
    "    raw_responses.append(raw)\n",
    "    \n",
    "\n",
    "\n",
    "df[\"pred\"]    = raw_responses\n",
    "\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Done! Responses written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6aa369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint details retrieval\n",
    "\n",
    "import requests\n",
    "\n",
    "api_key = key\n",
    "job_id = \"ft-jobID\"\n",
    "\n",
    "url = f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}/checkpoints\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf8830",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(r\"..\\prediction\\filename.csv\")\n",
    "\n",
    "# Map columns\n",
    "df['y_true'] = df['output']\n",
    "df['y_pred'] = df['pred'].str.lower().map({'positive': 1, 'negative': -1, 'neutral': 0})\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = (df['y_true'] == df['y_pred']).mean()\n",
    "print(f\"Overall accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "# Precision / Recall / F1\n",
    "report = classification_report(\n",
    "    df['y_true'], \n",
    "    df['y_pred'], \n",
    "    target_names=['negative', 'neutral', 'positive']\n",
    ")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
