{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Code for Encoder LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The finetuned model weights stored epoch by epoch, refer to the notes to find the best performing instace of each model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "file_names = {\"train\":r\"..\\input_data\\input_output_train.csv\",\"test\":r\"..\\input_data\\input_output_test.csv\"}\n",
    "dataset = datasets.load_dataset(\"csv\",data_files= file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as tm\n",
    "model_path = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = tm.AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_f(examples):\n",
    "    tokens = tokenizer(examples[\"input\"], truncation=True, padding=\"max_length\",max_length = 512)\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = dataset[\"train\"].map(tokenizer_f, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"output\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_dataset = dataset[\"test\"].map(tokenizer_f, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_dataset = tokenized_eval_dataset.rename_column(\"output\", \"labels\")\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(\"input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"google-bert/bert-base-uncased\"  # specify the model path as needed\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "tokenizer = tm.AutoTokenizer.from_pretrained(model_path)\n",
    "model = tm.AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",  \n",
    "    task_type=TaskType.SEQ_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "\n",
    "metric = load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "\n",
    "precision_metric = load(\"precision\")\n",
    "recall_metric = load(\"recall\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "\n",
    "    per_class_f1 = f1_metric.compute(predictions=predictions, references=labels, average=None)['f1']\n",
    "    per_class_precision = precision_metric.compute(predictions=predictions, references=labels, average=None)['precision']\n",
    "    per_class_recall = recall_metric.compute(predictions=predictions, references=labels, average=None)['recall']\n",
    "\n",
    "\n",
    "    macro_f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")['f1']\n",
    "    macro_precision = precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")['precision']\n",
    "    macro_recall = recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")['recall']\n",
    "    \n",
    "\n",
    "    metrics = {\n",
    "        'f1_macro': macro_f1,\n",
    "        'precision_macro': macro_precision,\n",
    "        'recall_macro': macro_recall,\n",
    "    }\n",
    "\n",
    "\n",
    "    for i, (p, r, f) in enumerate(zip(per_class_precision, per_class_recall, per_class_f1)):\n",
    "        metrics[f'precision_class_{i}'] = p\n",
    "        metrics[f'recall_class_{i}'] = r\n",
    "        metrics[f'f1_class_{i}'] = f\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=r\"trained_weights/bert-base-uncased/\",\n",
    "                                 num_train_epochs=10, \n",
    "                                 label_names=[\"labels\"],\n",
    "                                 learning_rate=3e-5,\n",
    "                                 save_strategy = \"epoch\",   #save weight after every epoch\n",
    "                                 per_device_train_batch_size=16,  \n",
    "                                 weight_decay=0.01, #prevent overfitting\n",
    "\n",
    "                                 logging_strategy=\"epoch\",\n",
    "                                 logging_dir=r\"trained_weights/bert-base-uncased/\",\n",
    "\n",
    "                                 eval_strategy = \"epoch\",\n",
    "                                 per_device_eval_batch_size=10,\n",
    "                                 load_best_model_at_end=True,\n",
    "                                 metric_for_best_model =\"eval_f1_macro\"\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Testing \n",
    "\n",
    "\n",
    "#### Pipeline can also be used here, but decided write the building blocks used within a pipeline to have more control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as tm\n",
    "model_path_huggingfacehub = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = tm.AutoTokenizer.from_pretrained(model_path_huggingfacehub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path_local = r\"/srv/scratch/z5503831/trainer_bert_base_uncased_5/checkpoint-405/\"\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = tm.AutoModelForSequenceClassification.from_pretrained(model_path_local, num_labels = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = dataset['test']['input'][13]\n",
    "dataset['test']['output'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(test_input, truncation = True, padding = \"max_length\", max_length = 512,return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits)\n",
    "\n",
    "print(f\"Predicted class: {predictions.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base-Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as tm\n",
    "\n",
    "analyser = tm.pipeline(\"sentiment-analysis\",  model = \"google-bert/bert-base-uncased\", truncation=True,max_length=512  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser(dataset['test']['input'][92])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_list = list(dataset['test']['input'])\n",
    "analyser(input_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "print(model.config.id2label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "zero_shot = pipeline(\"zero-shot-classification\", model=\"google-bert/bert-base-uncased\")\n",
    "res = zero_shot(\n",
    "    input_test_list,\n",
    "    candidate_labels=[\"negative\",\"neutral\",\"positive\"]\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Outputs for Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_name = \"google-bert/bert-base-uncased\" \n",
    "model_path_local =r\"trained_weights/bert-base-uncased/checkpoint-170\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForSequenceClassification.from_pretrained(\n",
    "                 model_path_local, num_labels=3\n",
    "             ).to(device)\n",
    "\n",
    "\n",
    "texts  = list(dataset[\"test\"][\"input\"])      # list of 152 strings\n",
    "labels = list(dataset[\"test\"][\"output\"])     # list of ints\n",
    "\n",
    "\n",
    "encodings = tokenizer(\n",
    "    texts,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    encodings[\"input_ids\"],\n",
    "    encodings[\"attention_mask\"],\n",
    "    torch.tensor(labels)\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    batch_size=32,      # feel free to tune\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, _ in test_loader:\n",
    "        input_ids     = input_ids.to(device)\n",
    "        attention_mask= attention_mask.to(device)\n",
    "\n",
    "        logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        ).logits\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "print(f\"Predictions for all {len(all_preds)} test examples:\\n\", all_preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
